# models/train_predictor.py
import joblib
import os
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression  # ‚Üê Chang√© ici

# Importer la fonction depuis mongo_client
from database.mongo_client import get_all_leads

# üîß D√©finir le chemin absolu du projet
PROJECT_ROOT = Path(__file__).parent.parent
MODEL_SAVE_PATH = PROJECT_ROOT / "models" / "saved" / "status_predictor.pkl"

def generate_training_data():
    """
    G√©n√®re les donn√©es d'entra√Ænement depuis MongoDB
    X = ["msg1", "msg1 ||| msg2", ...]
    y = [statut]
    """
    print("üîç Chargement des conversations depuis MongoDB...")
    try:
        conversations = get_all_leads()
    except Exception as e:
        raise Exception(f"‚ùå √âchec de chargement depuis MongoDB : {e}")

    if not conversations:
        raise Exception("‚ùå Aucune conversation trouv√©e. As-tu import√© les donn√©es ?")

    X, y = [], []
    valid_statuses = {"Qualified", "To follow up", "Unqualified"}

    for conv in conversations:
        status = conv.get("status")
        if not status or status not in valid_statuses:
            continue

        client_msgs = [
            msg["text"] for msg in conv.get("messages", [])
            if isinstance(msg, dict)
            and msg.get("sender_type") == "contact"
            and msg.get("text")
        ]

        if not client_msgs:
            continue

        for i in range(1, len(client_msgs) + 1):
            partial = " ||| ".join(client_msgs[:i])
            X.append(partial)
            y.append(status)

    print(f"‚úÖ {len(X)} exemples g√©n√©r√©s √† partir de {len(conversations)} conversations")
    return X, y


def train_predictor():
    """
    Entra√Æne un mod√®le LogisticRegression avec un TF-IDF optimis√©
    """
    try:
        X, y = generate_training_data()

        if len(X) < 5:
            raise ValueError("‚ùå Pas assez de donn√©es pour entra√Æner (minimum 5 exemples)")

        # ‚úÖ TF-IDF optimis√© pour le dialecte tunisien
        vectorizer = TfidfVectorizer(
            ngram_range=(1, 3),              # ‚Üê 1,2,3-grams pour capturer les phrases
            max_features=10000,              # ‚Üê Plus de features
            lowercase=True,
            stop_words=None,
            token_pattern=r'\b[a-zA-Z0-9]+\b'  # ‚Üê Garde les mots avec chiffres (ex: "10.5", "bac")
        )
        X_vec = vectorizer.fit_transform(X)

        # ‚úÖ Mod√®le : Logistic Regression (meilleure calibration que RF)
        model = LogisticRegression(
            random_state=42,
            class_weight="balanced",         # ‚Üê Compense les d√©s√©quilibres de classes
            max_iter=1000,
            C=1.0                            # ‚Üê R√©gularisation standard
        )
        model.fit(X_vec, y)

        # ‚úÖ Sauvegarde
        MODEL_SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)
        joblib.dump({
            "model": model,
            "vectorizer": vectorizer,
            "classes": sorted(list(set(y)))
        }, MODEL_SAVE_PATH)

        print(f"‚úÖ Mod√®le LR entra√Æn√© avec succ√®s !")
        print(f"   ‚Üí √âchantillons : {len(X)}")
        print(f"   ‚Üí Classes : {sorted(list(set(y)))}")
        print(f"   ‚Üí N-grams : {vectorizer.ngram_range}")
        print(f"   ‚Üí Sauvegard√© dans : {MODEL_SAVE_PATH}")

        return True

    except Exception as e:
        print(f"‚ùå Erreur lors de l'entra√Ænement : {str(e)}")
        return False